{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CloudDrive ML Security - Exploratory Data Analysis\n",
    "\n",
    "This notebook explores the upload logs and features extracted for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Raw Upload Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load upload logs\n",
    "df_logs = pd.read_csv('data/upload_logs.csv')\n",
    "print(f\"Total uploads: {len(df_logs)}\")\n",
    "print(f\"Unique users: {df_logs['user_id'].nunique()}\")\n",
    "print(f\"Unique IPs: {df_logs['ip_address'].nunique()}\")\n",
    "print(\"\\nFirst few records:\")\n",
    "print(df_logs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_counts = df_logs['success'].value_counts()\n",
    "success_rate = (success_counts[1] / len(df_logs)) * 100 if 1 in success_counts.index else 0\n",
    "\n",
    "print(f\"Successful uploads: {success_counts.get(1, 0)}\")\n",
    "print(f\"Failed uploads: {success_counts.get(0, 0)}\")\n",
    "print(f\"Success rate: {success_rate:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "df_logs['success'].value_counts().plot(kind='bar')\n",
    "plt.title('Upload Success vs Failure')\n",
    "plt.xlabel('Success (1=Yes, 0=No)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. File Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_logs = df_logs[df_logs['success'] == 1]\n",
    "file_sizes_mb = successful_logs['file_size'] / (1024 * 1024)\n",
    "\n",
    "print(f\"File size statistics (MB):\")\n",
    "print(f\"  Min: {file_sizes_mb.min():.2f}\")\n",
    "print(f\"  Max: {file_sizes_mb.max():.2f}\")\n",
    "print(f\"  Mean: {file_sizes_mb.mean():.2f}\")\n",
    "print(f\"  Median: {file_sizes_mb.median():.2f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(file_sizes_mb, bins=50, edgecolor='black')\n",
    "plt.xlabel('File Size (MB)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Upload File Sizes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. User Activity Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploads_per_user = df_logs.groupby('user_id').size()\n",
    "\n",
    "print(f\"Uploads per user:\")\n",
    "print(f\"  Min: {uploads_per_user.min()}\")\n",
    "print(f\"  Max: {uploads_per_user.max()}\")\n",
    "print(f\"  Mean: {uploads_per_user.mean():.2f}\")\n",
    "print(f\"  Median: {uploads_per_user.median():.2f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "uploads_per_user.plot(kind='bar')\n",
    "plt.xlabel('User ID')\n",
    "plt.ylabel('Number of Uploads')\n",
    "plt.title('Upload Activity by User')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Explore Extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('data/extracted_features.csv')\n",
    "print(f\"Features shape: {df_features.shape}\")\n",
    "print(\"\\nFeature columns:\")\n",
    "print(df_features.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Distributions by User Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "features_to_plot = ['uploads_per_time_window', 'duplicate_file_ratio', \n",
    "                    'average_file_size', 'upload_failure_rate']\n",
    "\n",
    "for idx, feature in enumerate(features_to_plot):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    normal_users = df_features[df_features['label'] == 0][feature]\n",
    "    attack_users = df_features[df_features['label'] == 1][feature]\n",
    "    \n",
    "    ax.hist(normal_users, bins=20, alpha=0.6, label='Normal', edgecolor='black')\n",
    "    ax.hist(attack_users, bins=20, alpha=0.6, label='Attack', edgecolor='black')\n",
    "    \n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Distribution: {feature}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['uploads_per_time_window', 'duplicate_file_ratio', 'average_file_size',\n",
    "                'upload_failure_rate', 'max_file_size', 'time_between_uploads_sec',\n",
    "                'total_uploads', 'total_bytes_uploaded']\n",
    "\n",
    "correlation_matrix = df_features[feature_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Predictions and Risk Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.read_csv('data/training_predictions.csv')\n",
    "\n",
    "print(f\"Anomalies detected: {(df_preds['prediction'] == -1).sum()}\")\n",
    "print(f\"Normal users: {(df_preds['prediction'] == 1).sum()}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(df_preds['anomaly_score'], bins=30, edgecolor='black')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Anomaly Scores')\n",
    "plt.axvline(0.65, color='orange', linestyle='--', label='Suspicious Threshold')\n",
    "plt.axvline(0.85, color='red', linestyle='--', label='Malicious Threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare true labels vs predictions\n",
    "print(\"User Classification Summary:\")\n",
    "print(\"\\nTrue Label Distribution:\")\n",
    "print(df_preds['label'].value_counts())\n",
    "\n",
    "print(\"\\nPredicted Anomalies (Model Output):\")\n",
    "print((df_preds['prediction'] == -1).value_counts())\n",
    "\n",
    "# Identify correctly and incorrectly classified users\n",
    "attack_users = df_preds[df_preds['label'] == 1]\n",
    "normal_users = df_preds[df_preds['label'] == 0]\n",
    "\n",
    "attack_detected = (attack_users['prediction'] == -1).sum()\n",
    "normal_misclassified = (normal_users['prediction'] == -1).sum()\n",
    "\n",
    "print(f\"\\nAttack Detection Rate: {attack_detected}/{len(attack_users)} = {(attack_detected/len(attack_users)*100):.1f}%\")\n",
    "print(f\"False Positive Rate: {normal_misclassified}/{len(normal_users)} = {(normal_misclassified/len(normal_users)*100):.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
